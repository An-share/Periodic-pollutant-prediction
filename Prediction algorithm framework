import pandas as pd
from pandas import read_csv
from datetime import datetime
from matplotlib import pyplot
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder,MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
from tensorflow.keras.models import Sequential
from keras.layers import Dense,Dropout
from keras.layers import LSTM
from numpy import concatenate
from math import sqrt
from pylab import mpl
# Read the data
df = pd.read_csv('file.csv',
                 parse_dates={'dt' : ['year', 'month', 'day','hour']},
                 #sep=";", 
                 infer_datetime_format=True,
                 low_memory=False, na_values=['nan','?'], index_col='dt')

df.drop('No', axis=1, inplace=True)
print(df.head(5))
new_index = pd.date_range(start='2010-01-01 00:00:00', periods=len(df), freq='H')
df.set_index(new_index, inplace=True)
df.index.name = 'dt'
print(df.head())
dataset_train_actual = df.copy()
dataset_train = df.copy()
print(dataset_train.shape)
print(dataset_train.head(5))
# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
training_set_scaled = sc.fit_transform(training_set)
sc_predict = StandardScaler()
sc_predict.fit_transform(training_set[:, 0:1])
X_train = []
y_train = []
n_future = 3 
n_past = 30 
for i in range(n_past, len(training_set_scaled) - n_future +1):
    X_train.append(training_set_scaled[i - n_past:i, [0, 1, 3,4,5]])
    y_train.append(training_set_scaled[i+n_future-1:i+n_future, 2])
X_train, y_train = np.array(X_train), np.array(y_train)

print('X_train shape == {}.'.format(X_train.shape))
print('y_train shape == {}.'.format(y_train.shape))
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)
print( X_train.shape)
print( X_test.shape)
print(y_train.shape)
print( y_test.shape)


X_train_concentration = X_train[ :, :, :4]  
X_train_angle = X_train[ :, :, 4:5]          
X_train_wind_speed = X_train[ :, :, 5:6]     
X_train_distance = X_train[:, :, 6:7]
print(X_train_concentration.shape)
print(X_train_angle.shape)
print(X_train_wind_speed.shape)
print(X_train_distance.shape)
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import Input, Conv2D, LSTM, Dense, Bidirectional, Dropout
from keras.layers import Reshape,Permute
from tensorflow.keras.layers import Lambda

def lr_schedule(epoch):
    initial_learning_rate = 1e-3
    decay_rate = 0.5
    decay_steps = 10
    if epoch < decay_steps:
        return initial_learning_rate
    else:
        return initial_learning_rate * decay_rate ** ((epoch - decay_steps) // decay_steps)
lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)
input_shape = X_train.shape[1:]
inputs = keras.Input(shape=input_shape)
print(inputs.shape)


#Specific content replacement of different models


def correlation_coefficient(y_true, y_pred):    
    mean_pred = tf.reduce_mean(y_pred)
    mean_true = tf.reduce_mean(y_true)
    xm = y_pred - mean_pred
    ym = y_true - mean_true
    r_num = tf.reduce_sum(tf.multiply(xm, ym))
    r_den = tf.sqrt(tf.reduce_sum(tf.square(xm)) * tf.reduce_sum(tf.square(ym)))
    r = r_num / r_den
    return r
def total_inertia_criterion(y_true, y_pred):    
    tss = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))
    rss = tf.reduce_sum(tf.square(y_true - y_pred))
    tic = 1 - (rss / tss)
    return tic
def index_of_agreement(y_true, y_pred):    
    mean_true = tf.reduce_mean(y_true)
    ia_numerator = tf.reduce_sum(tf.square(tf.subtract(y_true, y_pred)))
    ia_denominator = tf.reduce_sum(tf.square(tf.abs(tf.subtract(y_true, mean_true)))) + tf.reduce_sum(tf.square(tf.abs(tf.subtract(y_pred, mean_true))))
    ia = 1 - (ia_numerator / ia_denominator)
    return ia
model = tf.keras.Model(inputs=inputs, outputs=output)
model.compile(optimizer='adam', loss='mse', metrics=["msle", "mae", "mape", "RootMeanSquaredError", correlation_coefficient, total_inertia_criterion, index_of_agreement])
model.summary()
history = model.fit(X_train, y_train, epochs=150, validation_data=(X_test, y_test), callbacks=[lr_scheduler])
import pandas as pd
history_dict = history.history
history_df = pd.DataFrame(history_dict)
history_df.to_csv(results.csv', index=False)
from sklearn.metrics import r2_score
train_predictions = model.predict(X_train)
train_r2 = r2_score(y_train, train_predictions)
print(train_r2)
test_predictions = model.predict(X_test)
test_r2 = r2_score(y_test, test_predictions)
print(test_r2)
